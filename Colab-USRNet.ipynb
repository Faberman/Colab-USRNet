{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-USRNet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoG53_XDItU0",
        "colab_type": "text"
      },
      "source": [
        "This colab simply uses [KAIR](https://github.com/cszn/KAIR) as a base and contains some modifications and pre-configured cells. The goal was making the usage of USRNet userfriendly in colab.\n",
        "\n",
        "Here are examples: *coming soon*\n",
        "\n",
        "Notes:\n",
        "- Using 4x scale on all tests if possible.\n",
        " - waifu2x-ncnn-vulkan only 2x because waifu2x-ncnn-vulkan can't 4x.\n",
        "- Using different config values than the original KAIR. (Kernel 1.5 and noise 15.)\n",
        "- Using waifu2x default settings.\n",
        "- Gigapixel 4.4.5 without face stuff.\n",
        "\n",
        "\n",
        "Simple Tutorial:\n",
        "\n",
        "- Run cells with the Play-buttons that are visible on the right side of the code/text. ```[ ]``` indicate a Play-button.\n",
        "- Put your files in \"input\". That folder will appear with the path ```Google Drive/USRNet/input```. You can also create it yourself.\n",
        "- You can also input a .tar/.tar.gz file if you dont like using individial files to mitigate transfer time. Just run the correct cell for that. The default input path will be ```Google Drive/USRNet/input/data.tar``` or ```Google Drive/USRNet/input/data.tar.gz```.\n",
        "- After you are done, all files will be in ```Google Drive/USRNet/results```.\n",
        "\n",
        "Tip: You can split and merge images to mitigate VRAM with [IEU](https://github.com/ptrsuder/IEU.Winforms)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csbNmJmktUt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2WX7zYVSbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFWh9qvHtkUq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Run this at startup\n",
        "!git clone https://github.com/cszn/KAIR\n",
        "%cd /content/KAIR/model_zoo\n",
        "!pip install gdown\n",
        "!gdown --id 1qz8aaYOAMhoKn07VppFjRsDflYpxeVmz\n",
        "!gdown --id 1xPN26OW5YBN9-5QfK2BGnaovSutH7fLX\n",
        "!gdown --id 1R5HKJzHJmou-3iUYd4cNLSyMeWXSOmD4\n",
        "!gdown --id 1U4BV42Qf0dtBOVbhUNRay6di3j_ioZVM\n",
        "%cd /content/KAIR\n",
        "#!wget https://raw.githubusercontent.com/cszn/USRNet/master/main_test_realapplication.py\n",
        "!mkdir /content/KAIR/testsets/set_real\n",
        "#%cd /content/KAIR/testsets/set_real\n",
        "#!wget https://raw.githubusercontent.com/cszn/USRNet/master/testsets/set_real/chip.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spFbVXZyybC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Creates folders in your Google Drive for input and output.\n",
        "# You only need to apply this once.\n",
        "!mkdir \"/content/drive/My Drive/input\"\n",
        "!mkdir \"/content/drive/My Drive/results\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrsU7snAWJsd",
        "colab_type": "text"
      },
      "source": [
        "You can customize the python file yourself if you want, but the default will work as well. Interesting parameter:\n",
        "\n",
        "- model_name: Changes used model.\n",
        "- save_LE: If True, it will save a comparison.\n",
        "- noise_level_img: Configure noise level.\n",
        "- kernel_width_default_x1234: Configure Kernel size. Bigger Kernel will mean sharper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qRA62zL6Nc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile /content/KAIR/main_test_realapplication.py\n",
        "import os.path\n",
        "import cv2\n",
        "import logging\n",
        "import glob\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "from scipy.io import loadmat\n",
        "from scipy import ndimage\n",
        "import scipy.io as scio\n",
        "\n",
        "import torch\n",
        "\n",
        "from utils import utils_deblur\n",
        "from utils import utils_logger\n",
        "from utils import utils_sisr as sr\n",
        "from utils import utils_image as util\n",
        "\n",
        "from models.network_usrnet import USRNet as net\n",
        "\n",
        "'''\n",
        "Spyder (Python 3.7)\n",
        "PyTorch 1.4.0\n",
        "Windows 10 or Linux\n",
        "\n",
        "Kai Zhang (cskaizhang@gmail.com)\n",
        "github: https://github.com/cszn/USRNet\n",
        "        https://github.com/cszn/KAIR\n",
        "\n",
        "If you have any question, please feel free to contact with me.\n",
        "Kai Zhang (e-mail: cskaizhang@gmail.com)\n",
        "\n",
        "by Kai Zhang (12/March/2020)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "testing code of USRNet for the Table 1 in the paper\n",
        "@inproceedings{zhang2020deep,\n",
        "  title={Deep unfolding network for image super-resolution},\n",
        "  author={Zhang, Kai and Van Gool, Luc and Timofte, Radu},\n",
        "  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},\n",
        "  pages={3217--3226},\n",
        "  year={2020}\n",
        "}\n",
        "'''\n",
        "\n",
        "def main():\n",
        "    counter = 0\n",
        "    time_values = []\n",
        "    \n",
        "\n",
        "    rootdir = '/content/KAIR/testsets/'\n",
        "    files = glob.glob(rootdir + '/**/*.png', recursive=True)\n",
        "    files_jpg = glob.glob(rootdir + '/**/*.jpg', recursive=True)\n",
        "    files.extend(files_jpg)\n",
        "    \n",
        "    for f in files:\n",
        "      start = time.time()\n",
        "      counter += 1\n",
        "      \n",
        "      # ----------------------------------------\n",
        "      # Preparation\n",
        "      # ----------------------------------------\n",
        "      model_name = 'usrnet'      # 'usrgan' | 'usrnet' | 'usrgan_tiny' | 'usrnet_tiny'\n",
        "      testset_name = 'set_real'  # test set,  'set_real'\n",
        "      test_image = f    # 'chip.png', 'comic.png'\n",
        "      #test_image = 'comic.png'\n",
        "\n",
        "      sf = 4                     # scale factor, only from {1, 2, 3, 4}\n",
        "      show_img = False           # default: False\n",
        "      save_E = True              # save estimated image\n",
        "      save_LE = False             # save zoomed LR, Estimated images\n",
        "\n",
        "      # ----------------------------------------\n",
        "      # set noise level and kernel\n",
        "      # ----------------------------------------\n",
        "      if 'chip' in test_image:\n",
        "          noise_level_img = 15       # noise level for LR image, 15 for chip\n",
        "          kernel_width_default_x1234 = [0.6, 0.9, 1.7, 2.2] # Gaussian kernel widths for x1, x2, x3, x4\n",
        "      else:\n",
        "          noise_level_img = 15       # noise level for LR image, 0.5~3 for clean images\n",
        "          kernel_width_default_x1234 = [0.4, 0.7, 1.5, 1.5] # default Gaussian kernel widths of clean/sharp images for x1, x2, x3, x4\n",
        "\n",
        "      noise_level_model = noise_level_img/255.  # noise level of model\n",
        "      kernel_width = kernel_width_default_x1234[sf-1]\n",
        "\n",
        "      # set your own kernel width\n",
        "      # kernel_width = 2.2\n",
        "\n",
        "      k = utils_deblur.fspecial('gaussian', 25, kernel_width)\n",
        "      k = sr.shift_pixel(k, sf)  # shift the kernel\n",
        "      k /= np.sum(k)\n",
        "      util.surf(k) if show_img else None\n",
        "      # scio.savemat('kernel_realapplication.mat', {'kernel':k})\n",
        "\n",
        "      # load approximated bicubic kernels\n",
        "      #kernels = hdf5storage.loadmat(os.path.join('kernels', 'kernel_bicubicx234.mat'))['kernels']\n",
        "      #kernels = loadmat(os.path.join('kernels', 'kernel_bicubicx234.mat'))['kernels']\n",
        "      #kernel = kernels[0, sf-2].astype(np.float64)\n",
        "\n",
        "      kernel = util.single2tensor4(k[..., np.newaxis])\n",
        "\n",
        "\n",
        "      n_channels = 1 if 'gray' in  model_name else 3  # 3 for color image, 1 for grayscale image\n",
        "      model_pool = 'model_zoo'  # fixed\n",
        "      testsets = 'testsets'     # fixed\n",
        "      results = 'results'       # fixed\n",
        "      result_name = testset_name + '_' + model_name\n",
        "      model_path = os.path.join(model_pool, model_name+'.pth')\n",
        "\n",
        "      # ----------------------------------------\n",
        "      # L_path, E_path\n",
        "      # ----------------------------------------\n",
        "      L_path = os.path.join(testsets, testset_name) # L_path, fixed, for Low-quality images\n",
        "      E_path = os.path.join(results, result_name)   # E_path, fixed, for Estimated images\n",
        "      util.mkdir(E_path)\n",
        "\n",
        "      #logger_name = result_name\n",
        "      #utils_logger.logger_info(logger_name, log_path=os.path.join(E_path, logger_name+'.log'))\n",
        "      #logger = logging.getLogger(logger_name)\n",
        "\n",
        "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "      # ----------------------------------------\n",
        "      # load model\n",
        "      # ----------------------------------------\n",
        "      if 'tiny' in model_name:\n",
        "          model = net(n_iter=6, h_nc=32, in_nc=4, out_nc=3, nc=[16, 32, 64, 64],\n",
        "                      nb=2, act_mode=\"R\", downsample_mode='strideconv', upsample_mode=\"convtranspose\")\n",
        "      else:\n",
        "          model = net(n_iter=8, h_nc=64, in_nc=4, out_nc=3, nc=[64, 128, 256, 512],\n",
        "                      nb=2, act_mode=\"R\", downsample_mode='strideconv', upsample_mode=\"convtranspose\")\n",
        "\n",
        "      model.load_state_dict(torch.load(model_path), strict=True)\n",
        "      model.eval()\n",
        "      for key, v in model.named_parameters():\n",
        "          v.requires_grad = False\n",
        "\n",
        "      number_parameters = sum(map(lambda x: x.numel(), model.parameters()))\n",
        "      #logger.info('Params number: {}'.format(number_parameters))\n",
        "      model = model.to(device)\n",
        "      #logger.info('Model path: {:s}'.format(model_path))\n",
        "\n",
        "      #logger.info('model_name:{}, image sigma:{}'.format(model_name, noise_level_img))\n",
        "      #logger.info(L_path)\n",
        "\n",
        "      img = os.path.join(L_path, test_image)\n",
        "      # ------------------------------------\n",
        "      # (1) img_L\n",
        "      # ------------------------------------\n",
        "      img_name, ext = os.path.splitext(os.path.basename(img))\n",
        "      img_L = util.imread_uint(img, n_channels=n_channels)\n",
        "      img_L = util.uint2single(img_L)\n",
        "\n",
        "      util.imshow(img_L) if show_img else None\n",
        "      w, h = img_L.shape[:2]\n",
        "      #logger.info('{:>10s}--> ({:>4d}x{:<4d})'.format(img_name+ext, w, h))\n",
        "\n",
        "      # boundary handling\n",
        "      boarder = 8     # default setting for kernel size 25x25\n",
        "      img = cv2.resize(img_L, (sf*h, sf*w), interpolation=cv2.INTER_NEAREST)\n",
        "      img = utils_deblur.wrap_boundary_liu(img, [int(np.ceil(sf*w/boarder+2)*boarder), int(np.ceil(sf*h/boarder+2)*boarder)])\n",
        "      img_wrap = sr.downsample_np(img, sf, center=False)\n",
        "      img_wrap[:w, :h, :] = img_L\n",
        "      img_L = img_wrap\n",
        "\n",
        "      util.imshow(util.single2uint(img_L), title='LR image with noise level {}'.format(noise_level_img)) if show_img else None\n",
        "\n",
        "      img_L = util.single2tensor4(img_L)\n",
        "      img_L = img_L.to(device)\n",
        "\n",
        "      # ------------------------------------\n",
        "      # (2) img_E\n",
        "      # ------------------------------------\n",
        "      sigma = torch.tensor(noise_level_model).float().view([1, 1, 1, 1])\n",
        "      [img_L, kernel, sigma] = [el.to(device) for el in [img_L, kernel, sigma]]\n",
        "\n",
        "      img_E = model(img_L, kernel, sf, sigma)\n",
        "\n",
        "      img_E = util.tensor2uint(img_E)[:sf*w, :sf*h, ...]\n",
        "\n",
        "      if save_E:\n",
        "          util.imsave(img_E, os.path.join(E_path, img_name+'_x'+str(sf)+'_'+model_name+'.png'))\n",
        "\n",
        "      # --------------------------------\n",
        "      # (3) save img_LE\n",
        "      # --------------------------------\n",
        "      if save_LE:\n",
        "          k_v = k/np.max(k)*1.2\n",
        "          k_v = util.single2uint(np.tile(k_v[..., np.newaxis], [1, 1, 3]))\n",
        "          k_factor = 3\n",
        "          k_v = cv2.resize(k_v, (k_factor*k_v.shape[1], k_factor*k_v.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "          img_L = util.tensor2uint(img_L)[:w, :h, ...]\n",
        "          img_I = cv2.resize(img_L, (sf*img_L.shape[1], sf*img_L.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "          img_I[:k_v.shape[0], :k_v.shape[1], :] = k_v\n",
        "          util.imshow(np.concatenate([img_I, img_E], axis=1), title='LR / Recovered') if show_img else None\n",
        "          util.imsave(np.concatenate([img_I, img_E], axis=1), os.path.join(E_path, img_name+'_x'+str(sf)+'_'+model_name+'_LE.png'))\n",
        "\n",
        "      #loop_timer.update(end_time - start_time)\n",
        "      end = time.time()\n",
        "      final_time = end - start \n",
        "      time_values.append(final_time)\n",
        "      print('Image %d out of %d' %(counter,len(files)))\n",
        "\n",
        "      print(f\"********** Time per frame (avg): %d s Time left: %d s **********\" % ( (sum(time_values) / len(time_values)), (sum(time_values) / len(time_values)*(len(files)-counter))))\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kvi5oDlQRgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy Data (individual pictures) to Colab, run upscaling and copy back results to Google Drive. If you use another\n",
        "# model than usrnet, then you need to adjust the !cp path.\n",
        "# Example: !cp /content/KAIR/results/set_real_usrgan/* \"/content/drive/My Drive/USRNet/results/\"\n",
        "%cd /content/KAIR\n",
        "!cp /content/drive/My\\ Drive/USRNet/input/* /content/KAIR/testsets/set_real\n",
        "!python main_test_realapplication.py\n",
        "!cp /content/KAIR/results/set_real_usrnet/* \"/content/drive/My Drive/USRNet/results/\"\n",
        "print(\"Done.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEqBtQg5NQWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy .tar.gz to Colab, run upscaling, create .tar/.tar.gz and copy back archive to Google Drive.\n",
        "# If you want to use the 7z GUI, here is how you do it. With the 7z GUI you can create a .tar, then create a new\n",
        "# archive with only that file and select \"gzip\". You need to create an archive twice. The final file should be\n",
        "# data.tar.gz. You can change between .tar/.tar.gz in the last two lines. If .tar.gz is used, then compression\n",
        "# is applied.\n",
        "%cd /content/KAIR\n",
        "!cp \"/content/drive/My Drive/USRNet/input/data.tar.gz\" /content/KAIR/testsets/set_real/data.tar.gz\n",
        "!tar -C /content/KAIR/testsets/set_real/ -zxvf /content/KAIR/testsets/set_real/data.tar.gz\n",
        "!python main_test_realapplication.py\n",
        "!tar -cvf /content/KAIR/results/set_real_usrnet/output.tar.gz /content/KAIR/results/set_real_usrnet/\n",
        "!cp /content/KAIR/results/set_real_usrnet/output.tar.gz \"/content/drive/My Drive/USRNet/results/output.tar.gz\"\n",
        "print(\"Done.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_mIfzEFUpmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy .tar to Colab, run upscaling, create .tar/.tar.gz and copy back archive to Google Drive.\n",
        "# You can change between .tar/.tar.gz in the last two lines. If .tar.gz is used, then compression is applied.\n",
        "%cd /content/KAIR\n",
        "!cp \"/content/drive/My Drive/USRNet/input/data.tar\" /content/KAIR/testsets/set_real/data.tar\n",
        "!tar -C /content/KAIR/testsets/set_real/ -xvf /content/KAIR/testsets/set_real/data.tar\n",
        "!python main_test_realapplication.py\n",
        "!tar -cvf /content/KAIR/results/set_real_usrnet/output.tar.gz /content/KAIR/results/set_real_usrnet/\n",
        "!cp /content/KAIR/results/set_real_usrnet/output.tar.gz \"/content/drive/My Drive/USRNet/results/output.tar.gz\"\n",
        "print(\"Done.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjkinPp0zp0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [Optional] Clear upscaling folder in Colab\n",
        "%cd /content/\n",
        "!sudo rm -rf /content/KAIR/results/set_real_usrnet\n",
        "!mkdir /content/KAIR/results/set_real_usrnet\n",
        "\n",
        "!sudo rm -rf /content/KAIR/testsets\n",
        "!mkdir /content/KAIR/testsets\n",
        "!mkdir /content/KAIR/testsets/set_real"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNy7njd1tDaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [DEMO] USRNet demo\n",
        "# Place files in /content/KAIR/testsets/set5 and results will be in /content/KAIR/results/set5_usrnet.\n",
        "# This will create different low resolution files with different blur kernels and will show what\n",
        "# USRNet can do. Creates 36 low resolution files and the upscaled image result folder.\n",
        "%cd /content/KAIR\n",
        "!python /content/KAIR/main_test_usrnet.py"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
